{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d3e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Parâmetros (espelham o .m)\n",
    "# -----------------------------\n",
    "desvio_g = 1.0           # mGal (ruído)\n",
    "resolucao_graus = 0.05   # p/ borda no GeoTIFF (igual ao .m)\n",
    "d_lat = 0.5              # tamanho do bloco (°)\n",
    "d_long = 0.5             # tamanho do bloco (°)\n",
    "offset = 0.25            # margem extra (°)\n",
    "\n",
    "# Coeficientes polinomiais Xa (grau 9 como no seu exemplo .m)\n",
    "Xa = np.array([\n",
    "    226.783646281416,\n",
    "    -155.004524024261,\n",
    "    -3343.83283285998,\n",
    "    9976.21757061898,\n",
    "    -12499.9037185957,\n",
    "    8510.70347626656,\n",
    "    -3389.2325428571,\n",
    "    789.255025319892,\n",
    "    -99.6337374628924,\n",
    "    5.2686882195962,\n",
    "], dtype=float)\n",
    "\n",
    "# Arquivos de entrada/saída\n",
    "p_remove = Path(\"../REMOVER/remove_pontos.csv\")    # lat, lon, dg_res_calc_mgal\n",
    "p_grade  = Path(\"../GERACAO_GRADE_ANOMALIAS_RESIDUAIS/Grade_interpolar.txt\")\n",
    "p_tif    = Path(\"data/processed/Grade_AG_res_Poly9.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Leitura dos dados\n",
    "# -----------------------------\n",
    "rem = pd.read_csv(p_remove)\n",
    "Lat_all = rem[\"lat\"].to_numpy()\n",
    "Lon_all = rem[\"lon\"].to_numpy()\n",
    "G_all   = rem[\"dg_res_calc_mgal\"].to_numpy()\n",
    "N_all   = np.full_like(G_all, desvio_g, dtype=float)   # Desvios_g no .m\n",
    "\n",
    "grade = np.loadtxt(p_grade)  # 2 colunas: lat lon\n",
    "Lat_i_all = grade[:, 0]\n",
    "Lon_i_all = grade[:, 1]\n",
    "\n",
    "# -----------------------------\n",
    "# Funções auxiliares\n",
    "# -----------------------------\n",
    "def poly_cov(dist_deg, Xa, deg=None):\n",
    "    \"\"\"\n",
    "    C(dist) = a0 + a1*s + ... + a_n*s^n, com s em GRAUS (fiel ao .m).\n",
    "    deg=None -> usa len(Xa)-1; senão, trunca.\n",
    "    \"\"\"\n",
    "    if deg is None:\n",
    "        deg = len(Xa) - 1\n",
    "    # Vandermonde com potências 0..deg\n",
    "    powers = np.vstack([dist_deg**k for k in range(deg+1)]).T\n",
    "    return powers @ Xa[:deg+1]\n",
    "\n",
    "def lsc_poly(lon_i, lat_i, lon_obs, lat_obs, Xa, N_vec, G_vec, deg=None, nugget=0.0):\n",
    "    \"\"\"\n",
    "    Estima valores em (lon_i, lat_i) a partir dos observados por LSC usando covariância polinomial.\n",
    "    Distâncias em graus (mesma unidade do .m).\n",
    "    \"\"\"\n",
    "    # Matriz de distâncias obs-obs (graus)\n",
    "    dx_oo = lon_obs[:, None] - lon_obs[None, :]\n",
    "    dy_oo = lat_obs[:, None] - lat_obs[None, :]\n",
    "    s_oo = np.sqrt(dx_oo**2 + dy_oo**2)\n",
    "\n",
    "    Czz = poly_cov(s_oo, Xa, deg=deg)\n",
    "    # Regularização leve (se necessário)\n",
    "    if nugget > 0:\n",
    "        Czz = Czz + nugget*np.eye(Czz.shape[0])\n",
    "\n",
    "    # Soma diag(N) igual ao script\n",
    "    Czz = Czz + np.diag(N_vec)\n",
    "\n",
    "    # Distâncias grade-obs (graus)\n",
    "    dx_io = lon_i[:, None] - lon_obs[None, :]\n",
    "    dy_io = lat_i[:, None] - lat_obs[None, :]\n",
    "    s_io = np.sqrt(dx_io**2 + dy_io**2)\n",
    "\n",
    "    Csz = poly_cov(s_io, Xa, deg=deg)\n",
    "\n",
    "    # Resolve: (Czz)^{-1} G  via solve (mais estável)\n",
    "    sol = np.linalg.solve(Czz, G_vec)\n",
    "    G_hat = Csz @ sol\n",
    "    return G_hat\n",
    "\n",
    "# -----------------------------\n",
    "# Preparar blocos de interpolação\n",
    "# -----------------------------\n",
    "lat_min_i, lat_max_i = Lat_i_all.min(), Lat_i_all.max()\n",
    "lon_min_i, lon_max_i = Lon_i_all.min(), Lon_i_all.max()\n",
    "\n",
    "n_bloc_lat  = int(np.ceil((lat_max_i - lat_min_i) / d_lat))\n",
    "n_bloc_long = int(np.ceil((lon_max_i - lon_min_i) / d_long))\n",
    "\n",
    "# Vamos acumular resultados aqui\n",
    "out_lats, out_lons, out_vals = [], [], []\n",
    "\n",
    "# -----------------------------\n",
    "# Loop por blocos (fiel ao .m)\n",
    "# -----------------------------\n",
    "for bi in range(n_bloc_lat):\n",
    "    for bj in range(n_bloc_long):\n",
    "        # limites do bloco (sem offset)\n",
    "        min_lat = lat_min_i + bi*d_lat\n",
    "        max_lat = lat_min_i + (bi+1)*d_lat\n",
    "        min_lon = lon_min_i + bj*d_long\n",
    "        max_lon = lon_min_i + (bj+1)*d_long\n",
    "\n",
    "        # Seleciona observações dentro do bloco + offset (com borda)\n",
    "        lat_mask = (Lat_all >= (min_lat - offset)) & (Lat_all <= (max_lat + (offset if bi == n_bloc_lat-1 else offset)))\n",
    "        lon_mask = (Lon_all >= (min_lon - offset)) & (Lon_all <= (max_lon + (offset if bj == n_bloc_long-1 else offset)))\n",
    "        obs_mask = lat_mask & lon_mask\n",
    "\n",
    "        lat_obs = Lat_all[obs_mask]\n",
    "        lon_obs = Lon_all[obs_mask]\n",
    "        G_obs   = G_all[obs_mask]\n",
    "        N_obs   = N_all[obs_mask]\n",
    "\n",
    "        # Seleciona pontos da GRADE estritamente dentro do bloco (sem offset)\n",
    "        grid_mask = (Lat_i_all >= min_lat) & (Lat_i_all <= (max_lat if bi == n_bloc_lat-1 else max_lat)) & \\\n",
    "                    (Lon_i_all >= min_lon) & (Lon_i_all <= (max_lon if bj == n_bloc_long-1 else max_lon))\n",
    "\n",
    "        lat_i = Lat_i_all[grid_mask]\n",
    "        lon_i = Lon_i_all[grid_mask]\n",
    "\n",
    "        # Se não há pontos de grade nesse bloco, pula\n",
    "        if lat_i.size == 0:\n",
    "            continue\n",
    "        # Se há poucas observações, use vizinhos do bloco inteiro (fallback)\n",
    "        if lat_obs.size < 4:\n",
    "            # pega vizinhos num raio maior (ex.: 2*offset) — simples fallback\n",
    "            extra_mask = (Lat_all >= (min_lat - 2*offset)) & (Lat_all <= (max_lat + 2*offset)) & \\\n",
    "                         (Lon_all >= (min_lon - 2*offset)) & (Lon_all <= (max_lon + 2*offset))\n",
    "            lat_obs = Lat_all[extra_mask]\n",
    "            lon_obs = Lon_all[extra_mask]\n",
    "            G_obs   = G_all[extra_mask]\n",
    "            N_obs   = N_all[extra_mask]\n",
    "\n",
    "        # LSC com polinômio inteiro (grau = len(Xa)-1)\n",
    "        # Obs: no .m eles comentam versões truncadas; aqui usamos full.\n",
    "        G_hat = lsc_poly(lon_i, lat_i, lon_obs, lat_obs, Xa, N_obs, G_obs, deg=len(Xa)-1, nugget=0.0)\n",
    "\n",
    "        out_lats.append(lat_i)\n",
    "        out_lons.append(lon_i)\n",
    "        out_vals.append(G_hat)\n",
    "\n",
    "# Concatena resultados\n",
    "if len(out_vals) == 0:\n",
    "    raise RuntimeError(\"Nenhum bloco produziu resultados. Verifique máscaras, arquivos e limites.\")\n",
    "LATS = np.concatenate(out_lats)\n",
    "LONS = np.concatenate(out_lons)\n",
    "VALS = np.concatenate(out_vals)\n",
    "\n",
    "# Ordena por (lat, lon) como no MATLAB antes de reshape\n",
    "order = np.lexsort((LONS, LATS))\n",
    "LATS, LONS, VALS = LATS[order], LONS[order], VALS[order]\n",
    "\n",
    "# Reconstrói a grade\n",
    "lat_unique = np.unique(Lat_i_all)\n",
    "lon_unique = np.unique(Lon_i_all)\n",
    "nlin = lat_unique.size\n",
    "ncol = lon_unique.size\n",
    "\n",
    "# Mapeia (LATS,LONS) -> matriz [nlin x ncol]\n",
    "# (assumindo que Grade_interpolar.txt está em ordem de variação de long mais rápida)\n",
    "# Vamos garantir índice por grade estruturada:\n",
    "lat_to_idx = {v:i for i,v in enumerate(lat_unique)}\n",
    "lon_to_idx = {v:i for i,v in enumerate(lon_unique)}\n",
    "IMG = np.full((nlin, ncol), np.nan, dtype=float)\n",
    "for la, lo, va in zip(LATS, LONS, VALS):\n",
    "    i = lat_to_idx[la]\n",
    "    j = lon_to_idx[lo]\n",
    "    IMG[i, j] = va\n",
    "\n",
    "# -----------------------------\n",
    "# Escrever GeoTIFF\n",
    "# Limites com meia-célula (como no .m)\n",
    "# -----------------------------\n",
    "lat_S = lat_unique.min() - (resolucao_graus/2)\n",
    "lat_N = lat_unique.max() + (resolucao_graus/2)\n",
    "lon_W = lon_unique.min() - (resolucao_graus/2)\n",
    "lon_E = lon_unique.max() + (resolucao_graus/2)\n",
    "\n",
    "# Em rasterio, precisamos do transform e da orientação \"origem no canto superior-esquerdo\"\n",
    "# Nosso grid está indexado [lat crescente, lon crescente]; para o transform,\n",
    "# definimos origem em (lon_W, lat_N) e pixel size (dx=+res, dy=+res) mas com linha 0 = topo (lat_N -> decresce).\n",
    "# A solução simples: escrever invertendo o eixo lat (de cima para baixo).\n",
    "transform = from_origin(lon_W, lat_N, resolucao_graus, resolucao_graus)\n",
    "IMG_to_write = np.flipud(IMG)  # inverte no eixo vertical\n",
    "\n",
    "with rasterio.open(\n",
    "    p_tif, \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=IMG_to_write.shape[0],\n",
    "    width=IMG_to_write.shape[1],\n",
    "    count=1,\n",
    "    dtype=\"float32\",\n",
    "    crs=\"EPSG:4326\",\n",
    "    transform=transform,\n",
    ") as dst:\n",
    "    dst.write(IMG_to_write.astype(\"float32\"), 1)\n",
    "\n",
    "print(f\"OK! GeoTIFF salvo em: {p_tif.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physical-geodesy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
